{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--rerun] year month\n",
      "ipykernel_launcher.py: error: the following arguments are required: year, month\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import pyart\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "import argparse\n",
    "from csu_radartools import csu_fhc\n",
    "\n",
    "# Mapping from CSU indices to UHID values:\n",
    "# CSU: [NA, DZ (1), RN (2), CR (3), AG (4), WS (5), VI (6), LDG (7), HDG (8), HL (9), BD (10)]\n",
    "# SN:  [ 0, 1,   4,   1,   2,   7,   6,   11,  12,   13,  14]\n",
    "csu_to_sn = np.array([0, 3, 4, 1, 2, 7, 6, 11, 12, 13, 14])\n",
    "\n",
    "# Mapping from Py-ART indices to UHID values:\n",
    "# Py-ART: [DS (0), CR (1), LR (2), RP (3), RN (4), VI (5), WS (6), MH (7), HDG (8)]\n",
    "# SN:     [ 8,    1,   3,   5,   4,   6,   7,   9,   12]\n",
    "pyart_to_sn = np.array([0, 8, 1, 3, 5, 4, 6, 7, 9, 12])\n",
    "\n",
    "def setup_logging(output_dir):\n",
    "    log_file = os.path.join(output_dir, \"processing_log.log\")\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO,\n",
    "                        format='%(asctime)s %(message)s', filemode='w')\n",
    "    return log_file\n",
    "\n",
    "def read_radar(file, sweep=0):\n",
    "    radar = pyart.io.read(file)\n",
    "    #radar = radar.extract_sweeps([sweep])\n",
    "    return radar\n",
    "\n",
    "def csu_class(radar):\n",
    "    dbz = radar.fields['corrected_reflectivity']['data']\n",
    "    zdr = radar.fields['corrected_differential_reflectivity']['data']\n",
    "    kdp = radar.fields['corrected_specific_diff_phase']['data']\n",
    "    rhv = radar.fields['RHOHV']['data']\n",
    "    rtemp = radar.fields['sounding_temperature']['data']\n",
    "\n",
    "    scores = csu_fhc.csu_fhc_summer(dz=dbz, zdr=zdr, rho=rhv, kdp=kdp, use_temp=True, band='X', T=rtemp)\n",
    "    mapped_scores = csu_to_sn[scores]\n",
    "\n",
    "    radar = add_to_radar(mapped_scores, radar, field_name='csu_fhc_summer', units=\"category\",\n",
    "                         long_name='dual-polarization radar hydrometeor classification',\n",
    "                         standard_name='hydrometeor classification', dz_field='corrected_reflectivity')\n",
    "    return radar\n",
    "\n",
    "def pyart_class(radar):\n",
    "    radar.instrument_parameters['frequency'] = {'long_name': 'Radar frequency', 'units': 'Hz', 'data': [9.2e9]}\n",
    "\n",
    "    hydromet_class = pyart.retrieve.hydroclass_semisupervised(\n",
    "        radar,\n",
    "        refl_field=\"corrected_reflectivity\",\n",
    "        zdr_field=\"corrected_differential_reflectivity\",\n",
    "        kdp_field=\"filtered_corrected_specific_diff_phase\",\n",
    "        rhv_field=\"RHOHV\",\n",
    "        temp_field=\"sounding_temperature\",\n",
    "    )\n",
    "    mapped_hydromet_class = pyart_to_sn[hydromet_class['data']]\n",
    "\n",
    "    hydromet_class['data'] = mapped_hydromet_class\n",
    "    radar.add_field(\"pyart_hydroclass_semisupervised\", hydromet_class, replace_existing=True)\n",
    "    return radar\n",
    "\n",
    "def add_to_radar(field, radar, field_name, long_name, standard_name, units, dz_field):\n",
    "    fill_value = -32768\n",
    "    masked_field = np.ma.asanyarray(field)\n",
    "    masked_field.mask = masked_field == fill_value\n",
    "    if hasattr(radar.fields[dz_field]['data'], 'mask'):\n",
    "        setattr(masked_field, 'mask', np.logical_or(masked_field.mask, radar.fields[dz_field]['data'].mask))\n",
    "        fill_value = radar.fields[dz_field]['_FillValue']\n",
    "    field_dict = {\n",
    "        'data': masked_field,\n",
    "        'units': units,\n",
    "        'long_name': long_name,\n",
    "        'standard_name': standard_name,\n",
    "        '_FillValue': fill_value,\n",
    "        \"valid_min\": 0,\n",
    "        \"valid_max\": 14,\n",
    "        \"classification_description\": \"CSU and Py-ART hydrometeor classification\",\n",
    "        'command_used': \"pyart.retrieve.hydroclass_semisupervised(...)\"\n",
    "    }\n",
    "    radar.add_field(field_name, field_dict, replace_existing=True)\n",
    "    return radar\n",
    "\n",
    "def filter_fields(radar):\n",
    "    fields_to_keep = ['corrected_reflectivity', 'corrected_differential_reflectivity',\n",
    "                      'corrected_specific_diff_phase', 'RHOHV', 'sounding_temperature',\n",
    "                      'pyart_hydroclass_semisupervised', 'csu_fhc_summer']\n",
    "    radar.fields = {k: radar.fields[k] for k in fields_to_keep if k in radar.fields}\n",
    "    return radar\n",
    "\n",
    "def process_files(files, year, month):\n",
    "    output_dir = f'/gpfs/wolf2/arm/atm124/proj-shared/hydroclass/{year}{month}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    setup_logging(output_dir)\n",
    "    logging.info(f'Starting to process files for {year}-{month}')\n",
    "\n",
    "    for file in files:\n",
    "        logging.info(f'Processing file: {file}')\n",
    "        radar = read_radar(file)\n",
    "\n",
    "        radar = csu_class(radar)\n",
    "        radar = pyart_class(radar)\n",
    "        radar = filter_fields(radar)\n",
    "\n",
    "        # Extract timestamp part from filename and replace the prefix for output\n",
    "        file_basename = os.path.basename(file)\n",
    "        output_file = file_basename.replace('gucxprecipradarcmacppiS2.c1', 'gucxprecipradarcmachidS2.c1')\n",
    "\n",
    "        output_path = os.path.join(output_dir, output_file)\n",
    "        pyart.io.write_cfradial(output_path, radar, format='NETCDF4')\n",
    "\n",
    "        logging.info(f'Saved {output_path}')\n",
    "        del radar\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "def get_unprocessed_files(files, output_dir):\n",
    "    unprocessed_files = []\n",
    "    for file in files:\n",
    "        file_basename = os.path.basename(file)\n",
    "        output_file = file_basename.replace('gucxprecipradarcmacppiS2.c1', 'gucxprecipradarcmachidS2.c1')\n",
    "        output_path = os.path.join(output_dir, output_file)\n",
    "        if not os.path.exists(output_path):\n",
    "            unprocessed_files.append(file)\n",
    "    return unprocessed_files\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Process radar files for a given year and month\")\n",
    "    parser.add_argument(\"year\", default='2022', type=str, help=\"Year of the data (YYYY)\")\n",
    "    parser.add_argument(\"month\", default='08', type=str, help=\"Month of the data (MM)\")\n",
    "    parser.add_argument(\"--rerun\", action='store_true', help=\"If set, process all files again (even if already processed)\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    year = args.year\n",
    "    month = args.month\n",
    "    rerun = args.rerun\n",
    "\n",
    "    base_path = \"/gpfs/wolf2/arm/atm124/world-shared/gucxprecipradarcmacS2.c1/ppi/\"\n",
    "    glob_str = f\"{base_path}{year}{month}/gucxprecipradarcmacppiS2.c1.{year}{month}*.nc\"\n",
    "    files = sorted(glob.glob(glob_str))\n",
    "\n",
    "    output_dir = f'/gpfs/wolf2/arm/atm124/proj-shared/hydroclass/{year}{month}'\n",
    "    \n",
    "    if not rerun:\n",
    "        logging.info(f'Filtering out already processed files.')\n",
    "        files = get_unprocessed_files(files, output_dir)\n",
    "\n",
    "    if len(files) == 0:\n",
    "        logging.info(f'No files to process. All files already processed or directory empty.')\n",
    "    else:\n",
    "        logging.info(f'Found {len(files)} unprocessed files for processing in {glob_str}')\n",
    "        process_files(files, year, month)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
